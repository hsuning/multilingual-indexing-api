{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1362ed76",
   "metadata": {},
   "source": [
    "# MultilingualSentencesIndexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b60de9",
   "metadata": {},
   "source": [
    "This notebook aims to build an indexing model that can be used by an inference API. This API takes any input text and return the top N most probable FAQ_ids.\n",
    "\n",
    "To support the API, we will need a model that can retrieve questions related to any input. The model:\n",
    "- takes any input\n",
    "- encodes the input into embeddings\n",
    "- uses same similarity calculation method to get the similarity between input and all questions, by using their embeddings\n",
    "- return the top_n closest questions with FAQ_id and some other informations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0fd9f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Parameters-to-be-input-before-running\" data-toc-modified-id=\"Parameters-to-be-input-before-running-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Parameters to be input before running</a></span></li><li><span><a href=\"#Custom-Indexing-Model\" data-toc-modified-id=\"Custom-Indexing-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Custom Indexing Model</a></span></li><li><span><a href=\"#Build-model\" data-toc-modified-id=\"Build-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Build model</a></span></li><li><span><a href=\"#Verify\" data-toc-modified-id=\"Verify-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Verify</a></span></li><li><span><a href=\"#Save-Model\" data-toc-modified-id=\"Save-Model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Save Model</a></span></li><li><span><a href=\"#Next\" data-toc-modified-id=\"Next-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Next</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92484f",
   "metadata": {},
   "source": [
    "## Parameters to be input before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51db0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = '../data/extracted_n26_new.csv'\n",
    "output_file_path = '../data/closest_matches.csv'\n",
    "output_model_path = '../codes/multilingual_indexing_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306caa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelling\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_text import SentencepieceTokenizer\n",
    "\n",
    "# Save model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d185760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the previous results stored in csv (y/n)?y\n"
     ]
    }
   ],
   "source": [
    "# Load results built by MultilingualSentencesGrouping.ipynb \n",
    "result_df = pd.read_csv(output_file_path, index_col=0)\n",
    "result_df['FAQ_id'] = result_df['FAQ_id'].astype(int)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747e1e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the Preprocessor and Encoder (y/n)?y\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 09:31:43.793305: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-25 09:31:43.793573: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-11-25 09:31:46.048936: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-25 09:31:46.070104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Load modules from Tensorflow Hub\n",
    "preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\"\n",
    ")\n",
    "encoder = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base/1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35743633",
   "metadata": {},
   "source": [
    "## Custom Indexing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b81c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexing:\n",
    "    \"\"\"\n",
    "    Wrap all data into one class\n",
    "    \n",
    "    -------------------------\n",
    "    Args:\n",
    "        url (str): The webpage that we want to extract information\n",
    "\n",
    "    Returns:\n",
    "        sub_urls (set): a set (unique list) of urls found in the given webpage\n",
    "        title: the question extracted from the given webpage\n",
    "        content: the answer to the question\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, preprocessor, encoder, closest_matches_df):\n",
    "        # Store loaded modules to avoid reloading\n",
    "        self.preprocessor = preprocessor\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # All questions in closest_matches files\n",
    "        self.closest_matches_df = closest_matches_df\n",
    "        self.questions = list(set(closest_matches_df[\"question\"].values))\n",
    "        self.questions_embeds = None\n",
    "\n",
    "    def normalization(self, embeds):\n",
    "        \"\"\"\n",
    "        Use l2 normalization to embeddings\n",
    "        -------------------------\n",
    "        Args:\n",
    "            embeds (vector): embedding (high-dimensional) vectors produced by encoder\n",
    "\n",
    "        Returns:\n",
    "            norms_embeds (vector): normalized embedding (high-dimensional) vectors\n",
    "        \"\"\"\n",
    "        norms = np.linalg.norm(embeds, 2, axis=1, keepdims=True)\n",
    "        return embeds / norms\n",
    "\n",
    "    def embeddings(self, sentences):\n",
    "        \"\"\"\n",
    "        Encode raw sentences into embedding (high-dimensional) vectors\n",
    "        -------------------------\n",
    "        Args:\n",
    "            embeds (vector): embedding (high-dimensional) vectors\n",
    "\n",
    "        Returns:\n",
    "            norms_embeds (vector): normalized embedding (high-dimensional) vectors\n",
    "        \"\"\"\n",
    "        with tf.device('/cpu:0'):\n",
    "            sentences_embeds = tf.constant(sentences)\n",
    "            sentences_embeds = self.encoder(\n",
    "                self.preprocessor(sentences_embeds))[\"default\"]\n",
    "            # For semantic similarity tasks, apply l2 normalization to embeddings\n",
    "            sentences_embeds = self.normalization(sentences_embeds)\n",
    "        return sentences_embeds\n",
    "\n",
    "    def calculate_similarity(self, embeddings_1, embeddings_2, labels_1,\n",
    "                             labels_2):\n",
    "        \"\"\"\n",
    "        Calculate the similarity using arccos based text similarity\n",
    "        of two high-dimensional vectors\n",
    "        -------------------------\n",
    "        Args:\n",
    "            embeddings_1 (vector): embeddings produced by encoder\n",
    "            embeddings_2: embeddings produced by encoder\n",
    "            labels_1: texts in used for embeddings_1\n",
    "            labels_2: texts in used for embeddings_2\n",
    "\n",
    "        Returns:\n",
    "            df (dataframe): a pandas dataframe with three columns: \n",
    "            (texts in embeddings_1, texts in embeddings_2, similarity between two texts)\n",
    "        \"\"\"\n",
    "        assert len(embeddings_1) == len(labels_1)\n",
    "        assert len(embeddings_2) == len(labels_2)\n",
    "\n",
    "        # arccos based text similarity (Yang et al. 2019; Cer et al. 2019)\n",
    "        sim = 1 - np.arccos(cosine_similarity(embeddings_1,\n",
    "                                              embeddings_2)) / np.pi\n",
    "\n",
    "        embeddings_1_col, embeddings_2_col, sim_col = [], [], []\n",
    "        for i in range(len(embeddings_1)):\n",
    "            for j in range(len(embeddings_2)):\n",
    "                embeddings_1_col.append(labels_1[i])\n",
    "                embeddings_2_col.append(labels_2[j])\n",
    "                sim_col.append(sim[i][j])\n",
    "        df = pd.DataFrame(zip(embeddings_1_col, embeddings_2_col, sim_col),\n",
    "                          columns=['query', 'question', 'sim'])\n",
    "\n",
    "        df = df.fillna(1)\n",
    "        return df\n",
    "\n",
    "    def get_top_n_faqs(self, query, top_n):\n",
    "        \"\"\"\n",
    "        Get top N closest questions based on input text\n",
    "        -------------------------\n",
    "        Args:\n",
    "            query (str): the input text we want to classify against\n",
    "            top_n (int): the number of results we want to get\n",
    "\n",
    "        Returns:\n",
    "            res (dict): a dictionary like \n",
    "            {\"0\":{\"question\":\"Deposit fee\",\"Ranking\":1.0,\"FAQ_id\":132,\"locale\":\"en\",\"market\":\"en-de\"},\n",
    "            \"1\":{\"question\":\"Deposit fee\",\"Ranking\":1.0,\"FAQ_id\":132,\"locale\":\"en\",\"market\":\"en-it\"}\n",
    "        \"\"\"\n",
    "        query = [query]\n",
    "\n",
    "        query_embeds = self.embeddings(query)\n",
    "\n",
    "        res = self.calculate_similarity(query_embeds, self.questions_embeds,\n",
    "                                        query, self.questions).nlargest(\n",
    "                                            top_n, ['sim'])\n",
    "\n",
    "        res['Ranking'] = res['sim'].rank(ascending=False)\n",
    "        res = res.merge(self.closest_matches_df, how='left',\n",
    "                        on='question').drop(['query', 'sim'], axis=1)\n",
    "        res = res[:top_n].drop('answer', axis=1).T.to_dict()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c29721",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7469ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = Indexing(preprocessor, encoder, result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51f51f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No questions_embeds found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 09:31:59.490152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 09:31:59.747729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Take about 2 minutes\n",
    "# Add questions embeddings\n",
    "# Put outside to avoid rerunning\n",
    "try:\n",
    "    model.questions_embeds = questions_embeds\n",
    "except:\n",
    "    print('No questions_embeds found')\n",
    "    questions_embeds = model.embeddings(model.questions)\n",
    "    model.questions_embeds = questions_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33002827",
   "metadata": {},
   "source": [
    "## Verify\n",
    "\n",
    "In this section we show how to retrieve sentences related to a given input. Things to try:\n",
    "- Try a few different sample sentences\n",
    "- Try changing the number of returned results (they are returned in order of similarity)\n",
    "- Try cross-lingual capabilities by inputting texts in different languages (might want to use Google Translate on some results to your native language for sanity check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d51cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 09:33:22.162480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 09:33:22.401172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-de'},\n",
       " 1: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-it'},\n",
       " 2: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-fr'},\n",
       " 3: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-eu'},\n",
       " 4: {'question': 'Frais de dépôt',\n",
       "  'Ranking': 2.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'fr',\n",
       "  'market': 'fr-fr'},\n",
       " 5: {'question': 'Documentos bancarios',\n",
       "  'Ranking': 3.0,\n",
       "  'FAQ_id': 226,\n",
       "  'locale': 'es',\n",
       "  'market': 'es-es'},\n",
       " 6: {'question': 'Verwahrentgelt',\n",
       "  'Ranking': 4.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'de',\n",
       "  'market': 'de-de'},\n",
       " 7: {'question': 'Wie lange dauert eine Überweisung?',\n",
       "  'Ranking': 5.0,\n",
       "  'FAQ_id': 273,\n",
       "  'locale': 'de',\n",
       "  'market': 'de-at'},\n",
       " 8: {'question': 'Wie lange dauert eine Überweisung?',\n",
       "  'Ranking': 5.0,\n",
       "  'FAQ_id': 273,\n",
       "  'locale': 'de',\n",
       "  'market': 'de-de'},\n",
       " 9: {'question': 'Comment faire une réclamation ?',\n",
       "  'Ranking': 6.0,\n",
       "  'FAQ_id': 191,\n",
       "  'locale': 'fr',\n",
       "  'market': 'fr-fr'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "query = 'deposit fee'\n",
    "top_n = 10 \n",
    "\n",
    "model.get_top_n_faqs(query, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077a457",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09443ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cannot save tensorflow model in joblib\n",
    "# But we will reload it separately in API\n",
    "model.preprocessor = None\n",
    "model.encoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd2d2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_model_path, 'wb') as f:\n",
    "    joblib.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd63cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_model_path, 'rb') as f:\n",
    "    test = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb526ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.preprocessor = preprocessor\n",
    "test.encoder = encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe467ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 6 µs, total: 12 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-de'},\n",
       " 1: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-it'},\n",
       " 2: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-fr'},\n",
       " 3: {'question': 'Deposit fee',\n",
       "  'Ranking': 1.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'en',\n",
       "  'market': 'en-eu'},\n",
       " 4: {'question': 'Frais de dépôt',\n",
       "  'Ranking': 2.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'fr',\n",
       "  'market': 'fr-fr'},\n",
       " 5: {'question': 'Documentos bancarios',\n",
       "  'Ranking': 3.0,\n",
       "  'FAQ_id': 226,\n",
       "  'locale': 'es',\n",
       "  'market': 'es-es'},\n",
       " 6: {'question': 'Verwahrentgelt',\n",
       "  'Ranking': 4.0,\n",
       "  'FAQ_id': 132,\n",
       "  'locale': 'de',\n",
       "  'market': 'de-de'},\n",
       " 7: {'question': 'Wie lange dauert eine Überweisung?',\n",
       "  'Ranking': 5.0,\n",
       "  'FAQ_id': 273,\n",
       "  'locale': 'de',\n",
       "  'market': 'de-at'},\n",
       " 8: {'question': 'Wie lange dauert eine Überweisung?',\n",
       "  'Ranking': 5.0,\n",
       "  'FAQ_id': 273,\n",
       "  'locale': 'de',\n",
       "  'market': 'de-de'},\n",
       " 9: {'question': 'Comment faire une réclamation ?',\n",
       "  'Ranking': 6.0,\n",
       "  'FAQ_id': 191,\n",
       "  'locale': 'fr',\n",
       "  'market': 'fr-fr'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "query = 'deposit fee'\n",
    "top_n = 10 \n",
    "\n",
    "test.get_top_n_faqs(query, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e87927",
   "metadata": {},
   "source": [
    "## Next\n",
    "- Put the class in section 7 in /codes/MultilingualSentencesIndexing.py, so we can use it to build API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
